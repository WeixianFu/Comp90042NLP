{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "junior-football",
      "metadata": {
        "id": "junior-football"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sought-circle",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sought-circle",
        "outputId": "d62eaaf3-bd69-4438-9d71-9919bfee7226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 37.8 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 41.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 25.1 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 40 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 51 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 81 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 92 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 102 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 112 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 122 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 133 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 143 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 153 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 163 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 174 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 175 kB 14.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=b3628cf0dc081881ed2f87a57bf4f9285072b7a91b7faee249c20874412239a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVcNhs7PIW1a",
        "outputId": "78ce8aff-7995-47ee-9536-115e4a6d1bab"
      },
      "id": "BVcNhs7PIW1a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 14.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 63.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 83.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 8.6 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 81.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=cd8e612cd9e439d1e40819d3b8b6140c441659257afa4f2f6591fa001bdaab07\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "unlike-large",
      "metadata": {
        "id": "unlike-large"
      },
      "source": [
        "Note: In order to run BERTweet, you need to install the latest version of transformers:\n",
        "* `git clone https://github.com/huggingface/transformers.git`\n",
        "* `cd transformers`\n",
        "* `pip3 install --upgrade .`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "organized-owner",
      "metadata": {
        "id": "organized-owner"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import torch\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.nn import functional as F\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
        "from transformers import get_linear_schedule_with_warmup,AdamW,AutoModel, AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
        "from torch.utils.data import TensorDataset,DataLoader, RandomSampler, SequentialSampler, Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "working-prospect",
      "metadata": {
        "id": "working-prospect"
      },
      "source": [
        "Define some helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "smoking-chocolate",
      "metadata": {
        "id": "smoking-chocolate"
      },
      "outputs": [],
      "source": [
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "expected-monitor",
      "metadata": {
        "id": "expected-monitor"
      },
      "outputs": [],
      "source": [
        "def calculate_scores(preds, labels):\n",
        "    pred_flat = np.argmax(np.concatenate(preds), axis=1).flatten()\n",
        "    results = dict()\n",
        "    results['precision_score'] = precision_score(labels, pred_flat, average='binary')\n",
        "    results['recall_score'] = recall_score(labels, pred_flat, average='binary')\n",
        "    results['f1_score'] = f1_score(labels, pred_flat, average='binary')\n",
        "    return results\n",
        "\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "instant-alexander",
      "metadata": {
        "id": "instant-alexander"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "For BERTweet we will only load the data and do not perform any preprocessing at all (even links + usernames will not be removed from the input that we feed to BERTweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "identical-franchise",
      "metadata": {
        "id": "identical-franchise"
      },
      "outputs": [],
      "source": [
        "def convert_label(label):\n",
        "    if label == \"rumour\":\n",
        "        return 1\n",
        "    elif label == \"non-rumour\":\n",
        "        return 0\n",
        "    else:\n",
        "        raise Exception(\"label classes must be 'rumour' or 'non-rumour'\")\n",
        "        \n",
        "        \n",
        "def convert_prediction(pred):\n",
        "    if pred == 1:\n",
        "        return \"rumour\"\n",
        "    elif pred == 0:\n",
        "        return \"nonrumour\"\n",
        "    else:\n",
        "        raise Exception(\"prediction classes must be '0' or '1'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "committed-router",
      "metadata": {
        "id": "committed-router"
      },
      "outputs": [],
      "source": [
        "def load_data(data_file, label_file):\n",
        "    \n",
        "    if label_file != None:\n",
        "        y_true = json.load(open(label_file))\n",
        "    \n",
        "    with open(data_file, 'r') as data_train:\n",
        "        raw_list = list(data_train)\n",
        "\n",
        "    data_list = []\n",
        "\n",
        "\n",
        "    for event in raw_list:\n",
        "        tweets_in_event = json.loads(event)\n",
        "\n",
        "        tweet = {}\n",
        "\n",
        "        tweet['id'] = tweets_in_event[0]['id']\n",
        "        tweet['text'] = tweets_in_event[0]['text']\n",
        "        \n",
        "        # append text from follow-up tweets in tweet chain\n",
        "        follow_up_tweets = \"\"\n",
        "        for i in range(1, len(tweets_in_event)):\n",
        "            follow_up_tweets = follow_up_tweets + tweets_in_event[i]['text'] + \" \"\n",
        "        \n",
        "        # Concatenate text from all tweets in the field 'text'\n",
        "        tweet['text'] = tweet['text'] + \" \" + follow_up_tweets\n",
        "        \n",
        "        tweet['text'] = tweet['text'].strip()\n",
        "        \n",
        "        if label_file != None:\n",
        "            tweet['label'] = convert_label(y_true[str(tweet['id'])])\n",
        "        \n",
        "        data_list.append(tweet)\n",
        "\n",
        "    df = pd.DataFrame(data_list)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pj_U2nHMJx7u"
      },
      "id": "pj_U2nHMJx7u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "alleged-savage",
      "metadata": {
        "id": "alleged-savage"
      },
      "outputs": [],
      "source": [
        "# train_df = load_data(data_file = '../data/train.data.jsonl', label_file = '../data/train.label.json')\n",
        "# dev_df = load_data(data_file = '../data/dev.data.jsonl', label_file = '../data/dev.label.json')\n",
        "# test_df = load_data(data_file = '../data/test.data.jsonl', label_file = None)\n",
        "\n",
        "train_df = pd.read_csv('train_sr.csv')\n",
        "dev_df = pd.read_csv('dev_sr.csv')\n",
        "test_df = pd.read_csv('test_sr.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "private-railway",
      "metadata": {
        "id": "private-railway"
      },
      "source": [
        "# BERTweet model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "addressed-afghanistan",
      "metadata": {
        "id": "addressed-afghanistan"
      },
      "outputs": [],
      "source": [
        "def bert_encode(df, tokenizer):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for sentence in df[[\"text\"]].values:\n",
        "        sentence = sentence.item()\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            sentence,                      \n",
        "                            add_special_tokens = True,  \n",
        "                            max_length = 128,\n",
        "                            pad_to_max_length = True,\n",
        "                            truncation = True,\n",
        "                            return_attention_mask = True,   \n",
        "                            return_tensors = 'pt',    \n",
        "                    )\n",
        "           \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    inputs = {\n",
        "    'input_word_ids': input_ids,\n",
        "    'input_mask': attention_masks}\n",
        "\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "radio-extent",
      "metadata": {
        "id": "radio-extent"
      },
      "outputs": [],
      "source": [
        "def prepare_dataloaders(train_df,test_df,dev_df, batch_size):\n",
        "    # Load the AutoTokenizer with a normalization mode if the input Tweet is raw\n",
        "    \n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False, normalization=True)\n",
        "\n",
        "    tweet_valid = bert_encode(dev_df, tokenizer)\n",
        "    tweet_valid_labels = dev_df.label.astype(int)\n",
        "    tweet_valid_indexs = dev_df.index.astype(int)\n",
        "    \n",
        "    tweet_train = bert_encode(train_df, tokenizer)\n",
        "    tweet_train_labels = train_df.label.astype(int)\n",
        "    tweet_train_indexs = train_df.index.astype(int)\n",
        "    \n",
        "    tweet_test = bert_encode(test_df, tokenizer)\n",
        "    tweet_test_indexs = test_df.index.astype(int)\n",
        "\n",
        "    input_ids, attention_masks = tweet_train.values()\n",
        "    labels = torch.tensor(tweet_train_labels.values)\n",
        "    indexs = torch.tensor(tweet_train_indexs.values)\n",
        "    train_dataset = TensorDataset(input_ids, attention_masks, labels, indexs)\n",
        "    \n",
        "    input_ids, attention_masks = tweet_valid.values()\n",
        "    labels = torch.tensor(tweet_valid_labels.values)\n",
        "    indexs = torch.tensor(tweet_valid_indexs.values)\n",
        "    val_dataset = TensorDataset(input_ids, attention_masks, labels, indexs)\n",
        "    \n",
        "    input_ids, attention_masks = tweet_test.values()\n",
        "    indexs = torch.tensor(tweet_test_indexs.values)\n",
        "    test_dataset = TensorDataset(input_ids, attention_masks, indexs)\n",
        "\n",
        "    \n",
        "    train_dataloader = DataLoader(\n",
        "                train_dataset,\n",
        "                sampler = RandomSampler(train_dataset), \n",
        "                batch_size = batch_size \n",
        "            )\n",
        "\n",
        "\n",
        "    validation_dataloader = DataLoader(\n",
        "                val_dataset, \n",
        "                sampler = SequentialSampler(val_dataset),\n",
        "                batch_size = batch_size \n",
        "            )\n",
        "\n",
        "\n",
        "    test_dataloader = DataLoader(\n",
        "                test_dataset, \n",
        "                sampler = SequentialSampler(test_dataset), \n",
        "                batch_size = batch_size\n",
        "            )\n",
        "    \n",
        "    return train_dataloader,validation_dataloader,test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "occasional-graduate",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "0c8be21b5fe14fc5a5fc54855072b70c",
            "1ae1a184017d4d7e82c085532d81fc4f",
            "d651412732d449fe840380a02ddd87e7",
            "c69a2b728a88477fa89c74594076da3d",
            "2fe5e907495e4ee187dd8011e9483c4c",
            "3315aeae8e8b431cb3634c5574a45502",
            "1e2e2f83874340eeb944904dcbfd853b",
            "c2e7edc905a44febbed9e9810d9f21b1",
            "4f447f3fdffe410b844eb7066e76ced6",
            "2d09f84fb1da4c649975beb2bb040675",
            "ed136a5a4c8848d2a2eb23fa1dbe0727",
            "1198d058f938423f89963e538093b473",
            "a747d567db84426dbe8663100bab51c0",
            "d71ba793790340089d15ed43c074f9a7",
            "794c99e8c3e64120aaa9648e9512a294",
            "048c476a999b4e6ab47d6870e9708333",
            "3b825bfaafc0479c80864c6b8a92ccac",
            "d1791a34dc534a77a7b9263b62fdfd2f",
            "2d4775b074cd403080e10d741c50c2de",
            "d1c14de71bd44c2bbc0cde8d2e22910c",
            "47f3aaabed6d4908ae1e3065f161aa4f",
            "da266a1bc3aa479caf6da49bd96b507d",
            "c5aefc10f6e14037aaaf2eef70db4c58",
            "cab0e718082f428da7e14dbf8c5de734",
            "16adb8dc6e2741f09a7b7b9a32277778",
            "949debd66e144e8f8ac3da8d4aec78e9",
            "c6bf08c9bb7d4bdd9391ba3aa10f4504",
            "22f457e4e85a44268b07f73fcf500c8a",
            "67762459000640f4be90463b5404a943",
            "f8a71638edb84544a912905ec112dc7f",
            "b4fe672df31546588a2b5133ba455ab2",
            "a5cc96e7634f4bc68c7534bfb0d43f75",
            "232a4a0eedbf4eff97ec2c3d76dd75fe"
          ]
        },
        "id": "occasional-graduate",
        "outputId": "82eeeeea-1f89-4018-9efc-e5740b16ca35"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/558 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c8be21b5fe14fc5a5fc54855072b70c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/824k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1198d058f938423f89963e538093b473"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.03M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5aefc10f6e14037aaaf2eef70db4c58"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "train_dataloader,validation_dataloader,test_dataloader = prepare_dataloaders(train_df, test_df, dev_df, batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "invisible-atlantic",
      "metadata": {
        "id": "invisible-atlantic"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "varied-humidity",
      "metadata": {
        "id": "varied-humidity"
      },
      "outputs": [],
      "source": [
        "def test_encode(sentence):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False, normalization=True)\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sentence,                      \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 128,\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation = True,\n",
        "                        return_attention_mask = True,   \n",
        "                        return_tensors = 'pt',    \n",
        "                )\n",
        "           \n",
        "    return encoded_dict['input_ids']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "modular-cutting",
      "metadata": {
        "id": "modular-cutting"
      },
      "outputs": [],
      "source": [
        "def test_decode(tokens):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False, normalization=True)\n",
        "    return tokenizer.convert_ids_to_tokens(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "french-filing",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "french-filing",
        "outputId": "30d4becc-aa6b-488e-fb88-68d53a0e32e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4. Can eating garlic help prevent infection with the new coronavirus? #COVID19Malaysia https://t.co/q133xXBiwl 5. Can regularly rinsing your nose with saline help prevent infection with the new coronavirus? https://t.co/ccMjhhD7BK 6. Do vaccines against pneumonia protect you against the new coronavirus? https://t.co/wL0mlEqU95 7. Can spraying alcohol or chlorine all over your body kill the new coronavirus? #Chamber https://t.co/zunVR7Ht0V 8. How effective are thermal scanners in detecting people infected with the new coronavirus? https://t.co/nyLOyKAb1H 9. Can an ultraviolet disinfection lamp kill the new coronavirus? https://t.co/ZrlllbkIjm 10. Are hand dryers effective in killing the new coronavirus? https://t.co/cSDKXO1bGr 11. The new coronavirus CANNOT be transmitted through mosquito bites. https://t.co/ZRL8bjRkpl 12. Taking a hot bath does not prevent the new coronavirus disease https://t.co/bICOqSTOuD 13. Cold weather and snow CANNOT kill the new coronavirus. https://t.co/7yeQQ6gLNo 14. COVID-19 virus can be transmitted in areas with hot and humid climates https://t.co/ylKa2F40vu 15. Drinking alcohol does not protect you against COVID-19 and can be dangerous https://t.co/ZrLN61q046 16. Being able to hold your breath for 10 seconds or more without coughing or feeling discomfort DOES NOT mean you are free from the coronavirus disease (COVID-19) or any other lung disease. https://t.co/gPUL51Y2lx 17. You can recover from the coronavirus disease (COVID-19). Catching the new coronavirus DOES NOT mean you will have it for life. https://t.co/yrjUM5qniK 18. Exposing yourself to the sun or to temperatures higher than 25C degrees DOES NOT prevent the coronavirus disease (COVID-19) https://t.co/aOQKrrwaBv 19. 5G mobile networks DO NOT spread COVID-19 https://t.co/VjqelBmpTn'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "train_df.text[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "funny-island",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "funny-island",
        "outputId": "5409dc9d-ef23-429a-ea39-ddd6be2bc3a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape      : torch.Size([1, 128])\n",
            "Word Ids   : tensor([[    0,   204,     4,   427,  1114, 16282,   272,  5742, 12000,    30,\n",
            "             6,   127,  1456,    21, 41887,  8658,    10,   211,     4,   427,\n",
            "          9139, 23210,  1248,    44,  2756,    30,  4360,  1466,   272,  5742,\n",
            "         12000,    30,     6,   127,  1456,    21,    10,   339,     4,   172,\n",
            "         31965,   480, 38694,  2682,    14,   480,     6,   127,  1456,    21,\n",
            "            10,   380,     4,   427, 47043,  4273,    72, 24660,  1466,    48,\n",
            "           141,    44,   716,   897,     6,   127,  1456,    21,   995,  5553,\n",
            "          4281,    10,   440,     4,   203,  5433,    41, 29620,  2228, 37527,\n",
            "            16, 13486, 12120,    83, 12398,    30,     6,   127,  1456,    21,\n",
            "            10,   540,     4,   427,    74, 36037, 31902,  1215, 12000, 17693,\n",
            "           897,     6,   127,  1456,    21,    10,   251,     4,   533,   803,\n",
            "          4691, 19110,  5433,    16,  1863,     6,   127,  1456,    21,    10,\n",
            "           620,     4,    47,   127,  1456, 17282,    31,     2]])\n",
            "Decoded Words   : ['<s>', '4', '.', 'Can', 'eating', 'garlic', 'help', 'prevent', 'infection', 'with', 'the', 'new', 'coronavirus', '?', '#COVID19@@', 'Malaysia', 'HTTPURL', '5', '.', 'Can', 'regularly', 'rin@@', 'sing', 'your', 'nose', 'with', 'sal@@', 'ine', 'help', 'prevent', 'infection', 'with', 'the', 'new', 'coronavirus', '?', 'HTTPURL', '6', '.', 'Do', 'vaccines', 'against', 'pneumonia', 'protect', 'you', 'against', 'the', 'new', 'coronavirus', '?', 'HTTPURL', '7', '.', 'Can', 'spraying', 'alcohol', 'or', 'chlor@@', 'ine', 'all', 'over', 'your', 'body', 'kill', 'the', 'new', 'coronavirus', '?', '#C@@', 'ham@@', 'ber', 'HTTPURL', '8', '.', 'How', 'effective', 'are', 'thermal', 'sc@@', 'anners', 'in', 'det@@', 'ecting', 'people', 'infected', 'with', 'the', 'new', 'coronavirus', '?', 'HTTPURL', '9', '.', 'Can', 'an', 'ultra@@', 'violet', 'dis@@', 'infection', 'lamp', 'kill', 'the', 'new', 'coronavirus', '?', 'HTTPURL', '10', '.', 'Are', 'hand', 'dr@@', 'yers', 'effective', 'in', 'killing', 'the', 'new', 'coronavirus', '?', 'HTTPURL', '11', '.', 'The', 'new', 'coronavirus', 'CANNOT', 'be', '</s>']\n"
          ]
        }
      ],
      "source": [
        "text_test = train_df.text[0]\n",
        "text_encoded = test_encode(text_test)\n",
        "text_decoded = test_decode(text_encoded[0, :130])\n",
        "\n",
        "\n",
        "print(f'Shape      : {text_encoded.shape}')\n",
        "print(f'Word Ids   : {text_encoded}')\n",
        "print(f'Decoded Words   : {text_decoded}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dietary-transport",
      "metadata": {
        "id": "dietary-transport"
      },
      "source": [
        "## Prepare optimizer for BERTweet model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ranging-subsection",
      "metadata": {
        "id": "ranging-subsection"
      },
      "outputs": [],
      "source": [
        "def prepare_model(num_classes, model_to_load=None, total_steps=-1):\n",
        "\n",
        "    configuration = AutoConfig.from_pretrained('vinai/bertweet-base')\n",
        "    configuration.hidden_dropout_prob = 0\n",
        "    configuration.attention_probs_dropout_prob = 0\n",
        "    configuration.num_labels = num_classes\n",
        "    configuration.output_attentions = False\n",
        "    configuration.output_hidden_states = False\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        \"vinai/bertweet-base\",\n",
        "        config = configuration\n",
        "    )\n",
        "\n",
        "    optimizer = AdamW(model.parameters(),\n",
        "                    lr = 5e-5,\n",
        "                    eps = 1e-8,\n",
        "                    weight_decay = 1e-2\n",
        "                    )\n",
        "    \n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                                num_warmup_steps = 0, \n",
        "                                                num_training_steps = total_steps)\n",
        "\n",
        "    if model_to_load is not None:\n",
        "        model.roberta.load_state_dict(torch.load(model_to_load))\n",
        "        print(\"Loaded pre-trained model\")\n",
        "\n",
        "    return model, optimizer, scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "affecting-colors",
      "metadata": {
        "id": "affecting-colors"
      },
      "source": [
        "# BERTweet for development \n",
        "\n",
        "This BERTweet model was used for development purposes and makes use of the validation set to evaluate the performance on the given task."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "approximate-color",
      "metadata": {
        "id": "approximate-color"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "european-original",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "european-original",
        "outputId": "c3108ca5-5ed7-4488-ddeb-b6843f3f7de6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "model, optimizer, scheduler = prepare_model(num_classes=2, model_to_load=None, total_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "severe-arthur",
      "metadata": {
        "id": "severe-arthur"
      },
      "outputs": [],
      "source": [
        "def validate(model,validation_dataloader, val_labels):\n",
        "    model.eval()\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model.to(device)\n",
        "    \n",
        "    preds = []\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "    t0 = time.time()\n",
        "    \n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        preds.append(logits)\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "    \n",
        "    avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
        "    print(\"  Accuracy: {0:.3f} %\".format(avg_val_accuracy*100))\n",
        "    avg_val_loss = total_eval_loss / len(test_dataloader)\n",
        "    print(\"  Test Loss: {0:.3f}\".format(avg_val_loss))\n",
        "    \n",
        "    scores = calculate_scores(preds, val_labels)\n",
        "    print(\"  Precision Score: {0:.3f} %\".format(scores['precision_score']*100))\n",
        "    print(\"  Recall Score: {0:.3f} %\".format(scores['recall_score']*100))\n",
        "    print(\"  F1 Score: {0:.3f} %\".format(scores['f1_score']*100))\n",
        "\n",
        "    \n",
        "    return preds, avg_val_accuracy, avg_val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bigger-centre",
      "metadata": {
        "id": "bigger-centre"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, scheduler, train_dataloader, validation_dataloader, val_labels, epochs):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model.to(device)\n",
        "    \n",
        "    training_stats = []\n",
        "    total_t0 = time.time()\n",
        "\n",
        "    for epoch_i in range(0, epochs):\n",
        "\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training:')\n",
        "        \n",
        "        t0 = time.time()\n",
        "        total_train_loss = 0\n",
        "        model.train()\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            if step % 400 == 0 and not step == 0:\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "            \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "            model.zero_grad() \n",
        "            \n",
        "            outputs = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask, \n",
        "                                labels=b_labels)\n",
        "            \n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "            total_train_loss += loss.item()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epoch took: {:}\".format(training_time))\n",
        "            \n",
        "        _, avg_val_accuracy, avg_val_loss = validate(model,validation_dataloader, val_labels)\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Valid. Loss': avg_val_loss,\n",
        "                'Valid. Accur.': avg_val_accuracy,\n",
        "                'Training Time': training_time\n",
        "            }\n",
        "        )\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "architectural-scene",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "architectural-scene",
        "outputId": "8e770ed2-821d-40eb-91e8-41c066424870"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training:\n",
            "  Batch   400  of  2,836.    Elapsed: 0:01:25.\n",
            "  Batch   800  of  2,836.    Elapsed: 0:02:50.\n",
            "  Batch 1,200  of  2,836.    Elapsed: 0:04:15.\n",
            "  Batch 1,600  of  2,836.    Elapsed: 0:05:40.\n",
            "  Batch 2,000  of  2,836.    Elapsed: 0:07:05.\n",
            "  Batch 2,400  of  2,836.    Elapsed: 0:08:29.\n",
            "  Batch 2,800  of  2,836.    Elapsed: 0:09:54.\n",
            "\n",
            "  Training loss: 0.05\n",
            "  Training epoch took: 0:10:02\n",
            "  Accuracy: 107.156 %\n",
            "  Test Loss: 0.389\n",
            "  Precision Score: 84.151 %\n",
            "  Recall Score: 95.855 %\n",
            "  F1 Score: 89.622 %\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training:\n",
            "  Batch   400  of  2,836.    Elapsed: 0:01:25.\n",
            "  Batch   800  of  2,836.    Elapsed: 0:02:50.\n",
            "  Batch 1,200  of  2,836.    Elapsed: 0:04:14.\n",
            "  Batch 1,600  of  2,836.    Elapsed: 0:05:39.\n",
            "  Batch 2,000  of  2,836.    Elapsed: 0:07:04.\n",
            "  Batch 2,400  of  2,836.    Elapsed: 0:08:29.\n",
            "  Batch 2,800  of  2,836.    Elapsed: 0:09:53.\n",
            "\n",
            "  Training loss: 0.01\n",
            "  Training epoch took: 0:10:01\n",
            "  Accuracy: 108.633 %\n",
            "  Test Loss: 0.289\n",
            "  Precision Score: 93.860 %\n",
            "  Recall Score: 86.783 %\n",
            "  F1 Score: 90.183 %\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training:\n",
            "  Batch   400  of  2,836.    Elapsed: 0:01:25.\n",
            "  Batch   800  of  2,836.    Elapsed: 0:02:50.\n",
            "  Batch 1,200  of  2,836.    Elapsed: 0:04:14.\n",
            "  Batch 1,600  of  2,836.    Elapsed: 0:05:39.\n",
            "  Batch 2,000  of  2,836.    Elapsed: 0:07:04.\n",
            "  Batch 2,400  of  2,836.    Elapsed: 0:08:29.\n",
            "  Batch 2,800  of  2,836.    Elapsed: 0:09:53.\n",
            "\n",
            "  Training loss: 0.01\n",
            "  Training epoch took: 0:10:01\n",
            "  Accuracy: 105.357 %\n",
            "  Test Loss: 1.090\n",
            "  Precision Score: 80.113 %\n",
            "  Recall Score: 98.138 %\n",
            "  F1 Score: 88.214 %\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Training:\n",
            "  Batch   400  of  2,836.    Elapsed: 0:01:25.\n",
            "  Batch   800  of  2,836.    Elapsed: 0:02:49.\n",
            "  Batch 1,200  of  2,836.    Elapsed: 0:04:14.\n",
            "  Batch 1,600  of  2,836.    Elapsed: 0:05:39.\n",
            "  Batch 2,000  of  2,836.    Elapsed: 0:07:03.\n",
            "  Batch 2,400  of  2,836.    Elapsed: 0:08:28.\n",
            "  Batch 2,800  of  2,836.    Elapsed: 0:09:53.\n",
            "\n",
            "  Training loss: 0.01\n",
            "  Training epoch took: 0:10:00\n",
            "  Accuracy: 107.881 %\n",
            "  Test Loss: 0.876\n",
            "  Precision Score: 89.322 %\n",
            "  Recall Score: 90.207 %\n",
            "  F1 Score: 89.762 %\n",
            "\n",
            "======== Epoch 5 / 10 ========\n",
            "Training:\n",
            "  Batch   400  of  2,836.    Elapsed: 0:01:25.\n",
            "  Batch   800  of  2,836.    Elapsed: 0:02:49.\n",
            "  Batch 1,200  of  2,836.    Elapsed: 0:04:14.\n",
            "  Batch 1,600  of  2,836.    Elapsed: 0:05:39.\n",
            "  Batch 2,000  of  2,836.    Elapsed: 0:07:03.\n",
            "  Batch 2,400  of  2,836.    Elapsed: 0:08:28.\n",
            "  Batch 2,800  of  2,836.    Elapsed: 0:09:53.\n",
            "\n",
            "  Training loss: 0.01\n",
            "  Training epoch took: 0:10:00\n",
            "  Accuracy: 107.841 %\n",
            "  Test Loss: 0.729\n",
            "  Precision Score: 84.130 %\n",
            "  Recall Score: 97.777 %\n",
            "  F1 Score: 90.442 %\n",
            "\n",
            "======== Epoch 6 / 10 ========\n",
            "Training:\n",
            "  Batch   400  of  2,836.    Elapsed: 0:01:25.\n",
            "  Batch   800  of  2,836.    Elapsed: 0:02:49.\n",
            "  Batch 1,200  of  2,836.    Elapsed: 0:04:14.\n",
            "  Batch 1,600  of  2,836.    Elapsed: 0:05:38.\n",
            "  Batch 2,000  of  2,836.    Elapsed: 0:07:03.\n",
            "  Batch 2,400  of  2,836.    Elapsed: 0:08:28.\n",
            "  Batch 2,800  of  2,836.    Elapsed: 0:09:52.\n",
            "\n",
            "  Training loss: 0.01\n",
            "  Training epoch took: 0:10:00\n",
            "  Accuracy: 106.941 %\n",
            "  Test Loss: 0.835\n",
            "  Precision Score: 82.781 %\n",
            "  Recall Score: 97.627 %\n",
            "  F1 Score: 89.593 %\n",
            "\n",
            "======== Epoch 7 / 10 ========\n",
            "Training:\n",
            "  Batch   400  of  2,836.    Elapsed: 0:01:25.\n",
            "  Batch   800  of  2,836.    Elapsed: 0:02:49.\n",
            "  Batch 1,200  of  2,836.    Elapsed: 0:04:14.\n",
            "  Batch 1,600  of  2,836.    Elapsed: 0:05:39.\n",
            "  Batch 2,000  of  2,836.    Elapsed: 0:07:03.\n",
            "  Batch 2,400  of  2,836.    Elapsed: 0:08:28.\n",
            "  Batch 2,800  of  2,836.    Elapsed: 0:09:52.\n",
            "\n",
            "  Training loss: 0.01\n",
            "  Training epoch took: 0:10:00\n",
            "  Accuracy: 110.567 %\n",
            "  Test Loss: 0.495\n",
            "  Precision Score: 92.221 %\n",
            "  Recall Score: 93.301 %\n",
            "  F1 Score: 92.758 %\n",
            "\n",
            "======== Epoch 8 / 10 ========\n",
            "Training:\n",
            "  Batch   400  of  2,836.    Elapsed: 0:01:25.\n",
            "  Batch   800  of  2,836.    Elapsed: 0:02:49.\n",
            "  Batch 1,200  of  2,836.    Elapsed: 0:04:14.\n",
            "  Batch 1,600  of  2,836.    Elapsed: 0:05:39.\n",
            "  Batch 2,000  of  2,836.    Elapsed: 0:07:03.\n",
            "  Batch 2,400  of  2,836.    Elapsed: 0:08:28.\n",
            "  Batch 2,800  of  2,836.    Elapsed: 0:09:52.\n",
            "\n",
            "  Training loss: 0.01\n",
            "  Training epoch took: 0:10:00\n",
            "  Accuracy: 111.775 %\n",
            "  Test Loss: 0.493\n",
            "  Precision Score: 91.417 %\n",
            "  Recall Score: 97.266 %\n",
            "  F1 Score: 94.251 %\n",
            "\n",
            "======== Epoch 9 / 10 ========\n",
            "Training:\n",
            "  Batch   400  of  2,836.    Elapsed: 0:01:25.\n",
            "  Batch   800  of  2,836.    Elapsed: 0:02:49.\n",
            "  Batch 1,200  of  2,836.    Elapsed: 0:04:14.\n",
            "  Batch 1,600  of  2,836.    Elapsed: 0:05:39.\n",
            "  Batch 2,000  of  2,836.    Elapsed: 0:07:03.\n",
            "  Batch 2,400  of  2,836.    Elapsed: 0:08:28.\n",
            "  Batch 2,800  of  2,836.    Elapsed: 0:09:53.\n",
            "\n",
            "  Training loss: 0.01\n",
            "  Training epoch took: 0:10:00\n",
            "  Accuracy: 109.922 %\n",
            "  Test Loss: 0.618\n",
            "  Precision Score: 92.518 %\n",
            "  Recall Score: 91.379 %\n",
            "  F1 Score: 91.945 %\n",
            "\n",
            "======== Epoch 10 / 10 ========\n",
            "Training:\n",
            "  Batch   400  of  2,836.    Elapsed: 0:01:25.\n",
            "  Batch   800  of  2,836.    Elapsed: 0:02:49.\n",
            "  Batch 1,200  of  2,836.    Elapsed: 0:04:14.\n",
            "  Batch 1,600  of  2,836.    Elapsed: 0:05:39.\n",
            "  Batch 2,000  of  2,836.    Elapsed: 0:07:03.\n",
            "  Batch 2,400  of  2,836.    Elapsed: 0:08:28.\n",
            "  Batch 2,800  of  2,836.    Elapsed: 0:09:53.\n",
            "\n",
            "  Training loss: 0.01\n",
            "  Training epoch took: 0:10:00\n",
            "  Accuracy: 109.358 %\n",
            "  Test Loss: 0.673\n",
            "  Precision Score: 92.474 %\n",
            "  Recall Score: 90.057 %\n",
            "  F1 Score: 91.249 %\n",
            "\n",
            "Training complete!\n",
            "Total training took 1:50:44 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "train(model,optimizer,scheduler,train_dataloader,validation_dataloader, dev_df.label.astype(int), epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "revolutionary-rabbit",
      "metadata": {
        "id": "revolutionary-rabbit"
      },
      "outputs": [],
      "source": [
        "torch.save(model.cpu().roberta.state_dict(),\"model_sr\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qntiTbQBdHsR"
      },
      "id": "qntiTbQBdHsR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAA0hRYpdH3M",
        "outputId": "6ca5738d-c772-4246-e6d6-20223adf3060"
      },
      "id": "RAA0hRYpdH3M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.cpu().roberta.state_dict(),F\"/content/drive/MyDrive/Colab/model_sr1\")"
      ],
      "metadata": {
        "id": "8iLZBWEsdRKI"
      },
      "id": "8iLZBWEsdRKI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "enclosed-wesley",
      "metadata": {
        "id": "enclosed-wesley"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rough-artist",
      "metadata": {
        "id": "rough-artist"
      },
      "outputs": [],
      "source": [
        "def predict(model, test_dataloader):\n",
        "    model.eval()\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model.to(device)\n",
        "    preds = []\n",
        "\n",
        "    for batch in test_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        for logit in logits:\n",
        "            preds.append(logit)\n",
        "\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_dev = predict(model,validation_dataloader)"
      ],
      "metadata": {
        "id": "FQgIkVCXhsbI"
      },
      "id": "FQgIkVCXhsbI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax\n",
        "pred_scores = softmax(result_dev, axis=1)[:, 1]\n",
        "index_list = list(dev_df['index'])\n",
        "label_all = list(dev_df['label'])\n",
        "\n",
        "from collections import Counter, defaultdict\n",
        "counter = Counter(index_list)\n",
        "proba_sum = defaultdict(float)\n",
        "label_sum = defaultdict(int)\n",
        "\n",
        "for i in range(len(index_list)):\n",
        "  proba_sum[index_list[i]] += pred_scores[i]\n",
        "  label_sum[index_list[i]] += label_all[i]\n",
        "pred_labels = []\n",
        "proba_list = []\n",
        "label_list = []\n",
        "for i in sorted(list(proba_sum.keys())):\n",
        "  proba = 0\n",
        "  label = 0\n",
        "  proba_list.append(proba_sum[i]/counter[i])\n",
        "  label_list.append(int(label_sum[i]/counter[i]))\n",
        "  if proba_sum[i]/counter[i]>0.5:\n",
        "    label = 1\n",
        "  pred_labels.append(label)\n",
        "\n",
        "print(len(proba_list))\n",
        "print(len(label_list))\n",
        "# assert len(proba_list)==len(label_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbDQZgiAhxOV",
        "outputId": "f508b926-eefc-4785-e58a-0cd0000af832"
      },
      "id": "JbDQZgiAhxOV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "537\n",
            "537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "print(metrics.accuracy_score(label_list, pred_labels))\n",
        "print(metrics.precision_score(label_list, pred_labels))\n",
        "print(metrics.recall_score(label_list, pred_labels))\n",
        "print(metrics.roc_auc_score(label_list, proba_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOOUbIeFmbNz",
        "outputId": "08584441-a63d-4161-e6e7-9e1cb43e5161"
      },
      "id": "ZOOUbIeFmbNz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9553072625698324\n",
            "0.9504950495049505\n",
            "0.8347826086956521\n",
            "0.9263548320626416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "conservative-section",
      "metadata": {
        "id": "conservative-section"
      },
      "outputs": [],
      "source": [
        "result = predict(model,test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DYEwAcAicAJe"
      },
      "id": "DYEwAcAicAJe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax\n",
        "pred_scores = softmax(result, axis=1)[:, 1]\n",
        "index_list = list(test_df['index'])\n",
        "\n",
        "from collections import Counter, defaultdict\n",
        "counter = Counter(index_list)\n",
        "proba_sum = defaultdict(float)\n",
        "\n",
        "for i in range(len(index_list)):\n",
        "  proba_sum[index_list[i]] += pred_scores[i]\n",
        "\n",
        "pred_labels = []\n",
        "for i in sorted(list(proba_sum.keys())):\n",
        "  label = 0\n",
        "  if proba_sum[i]/counter[i]>0.5:\n",
        "    label = 1\n",
        "  pred_labels.append(label)\n",
        "\n",
        "with open('test.predictions1.txt', 'w') as output:\n",
        "  output.write('Id,Predicted\\n')\n",
        "  counter = 0\n",
        "  for elem in pred_labels:\n",
        "    output.write(str(counter) + ',' + str(elem)+'\\n')\n",
        "    counter+=1\n",
        "  \n"
      ],
      "metadata": {
        "id": "Unl2Y_WePVv_"
      },
      "id": "Unl2Y_WePVv_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "metric-profile",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "metric-profile",
        "outputId": "597597fe-005e-4b7c-9a1a-4a18a74c5e9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      id     target\n",
              "0    1246482832316301319  nonrumour\n",
              "1    1252279738099433473  nonrumour\n",
              "2    1236050255394877440  nonrumour\n",
              "3    1235582115900796928  nonrumour\n",
              "4    1258787515592572928  nonrumour\n",
              "..                   ...        ...\n",
              "553   427944719612915712  nonrumour\n",
              "554   531206167302012929  nonrumour\n",
              "555   553099685888790528     rumour\n",
              "556  1222928724112396288  nonrumour\n",
              "557  1239324381215707139  nonrumour\n",
              "\n",
              "[558 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4e568fd-5aac-42a6-ade8-7963443a0a6e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1246482832316301319</td>\n",
              "      <td>nonrumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1252279738099433473</td>\n",
              "      <td>nonrumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1236050255394877440</td>\n",
              "      <td>nonrumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1235582115900796928</td>\n",
              "      <td>nonrumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1258787515592572928</td>\n",
              "      <td>nonrumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553</th>\n",
              "      <td>427944719612915712</td>\n",
              "      <td>nonrumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>531206167302012929</td>\n",
              "      <td>nonrumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>553099685888790528</td>\n",
              "      <td>rumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>1222928724112396288</td>\n",
              "      <td>nonrumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>1239324381215707139</td>\n",
              "      <td>nonrumour</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>558 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4e568fd-5aac-42a6-ade8-7963443a0a6e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4e568fd-5aac-42a6-ade8-7963443a0a6e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4e568fd-5aac-42a6-ade8-7963443a0a6e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "pred_labels = np.argmax(result, axis = 1)\n",
        "\n",
        "with open('test.predictions.txt', 'w') as output:\n",
        "  output.write('Id,Predicted\\n')\n",
        "  counter = 0\n",
        "  for elem in list(pred_labels):\n",
        "    output.write(str(counter) + ',' + str(elem)+'\\n')\n",
        "    counter+=1\n",
        "\n",
        "pred_scores = softmax(result, axis=1)[:, 1]\n",
        "\n",
        "predicted_labels = [convert_prediction(pred) for pred in pred_labels]\n",
        "\n",
        "output = pd.DataFrame({'id':test_df.id,'target':predicted_labels})\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caroline-discrimination",
      "metadata": {
        "id": "caroline-discrimination"
      },
      "outputs": [],
      "source": [
        "submission = pd.Series(output.target.values,index=output.id).to_dict()\n",
        "with open('test-output_v21.json', 'w') as f:\n",
        "    json.dump(submission, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ideal-bermuda",
      "metadata": {
        "id": "ideal-bermuda"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "labeled-yeast",
      "metadata": {
        "id": "labeled-yeast"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "preliminary-conclusion",
      "metadata": {
        "id": "preliminary-conclusion"
      },
      "source": [
        "# BERTweet for CodaLab submission"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "harmful-processing",
      "metadata": {
        "id": "harmful-processing"
      },
      "source": [
        "For the CodaLab compeition, the train and development dataset has been merged to increase the size of the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "anonymous-walnut",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "anonymous-walnut",
        "outputId": "b38cf0ae-72e1-49cf-eb1e-cd3084b22630"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0                                               text  label  \\\n",
              "0              0  4. Can eating garlic help prevent infection wi...      0   \n",
              "1              1  French police chief killed himself after #Char...      1   \n",
              "2              2  Coronavirus disease (COVID-19) advice for the ...      0   \n",
              "3              3  Ottawa police confirm that there were multiple...      0   \n",
              "4              4  if the primary focus of a government isn't to ...      0   \n",
              "...          ...                                                ...    ...   \n",
              "2397         590  WHAT ARE THE TREATMENT OPTIONS FOR COVID-19 (I...      0   \n",
              "2398         591  After speculation that he’s been arrested, Ban...      1   \n",
              "2399         592  *Your questions answered*❓\\n\\n*Reply with the ...      0   \n",
              "2400         593  ►#Anonymous Operation #KKK ►Ku Klux Klan, We n...      1   \n",
              "2401         594  Just as fast as the virus has spread so has th...      0   \n",
              "\n",
              "                       id  \n",
              "0     1250219300389974016  \n",
              "1      554886875303780352  \n",
              "2     1237901309011021825  \n",
              "3      524958128392376320  \n",
              "4     1239295488677085185  \n",
              "...                   ...  \n",
              "2397  1249582429565829120  \n",
              "2398   524881688825167872  \n",
              "2399  1240908749256232960  \n",
              "2400   661102820976930816  \n",
              "2401  1248261299160612870  \n",
              "\n",
              "[2402 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73a7076d-38b0-4edf-8c75-62f8b8c03c93\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>4. Can eating garlic help prevent infection wi...</td>\n",
              "      <td>0</td>\n",
              "      <td>1250219300389974016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>French police chief killed himself after #Char...</td>\n",
              "      <td>1</td>\n",
              "      <td>554886875303780352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Coronavirus disease (COVID-19) advice for the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1237901309011021825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Ottawa police confirm that there were multiple...</td>\n",
              "      <td>0</td>\n",
              "      <td>524958128392376320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>if the primary focus of a government isn't to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1239295488677085185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2397</th>\n",
              "      <td>590</td>\n",
              "      <td>WHAT ARE THE TREATMENT OPTIONS FOR COVID-19 (I...</td>\n",
              "      <td>0</td>\n",
              "      <td>1249582429565829120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2398</th>\n",
              "      <td>591</td>\n",
              "      <td>After speculation that he’s been arrested, Ban...</td>\n",
              "      <td>1</td>\n",
              "      <td>524881688825167872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2399</th>\n",
              "      <td>592</td>\n",
              "      <td>*Your questions answered*❓\\n\\n*Reply with the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1240908749256232960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2400</th>\n",
              "      <td>593</td>\n",
              "      <td>►#Anonymous Operation #KKK ►Ku Klux Klan, We n...</td>\n",
              "      <td>1</td>\n",
              "      <td>661102820976930816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2401</th>\n",
              "      <td>594</td>\n",
              "      <td>Just as fast as the virus has spread so has th...</td>\n",
              "      <td>0</td>\n",
              "      <td>1248261299160612870</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2402 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73a7076d-38b0-4edf-8c75-62f8b8c03c93')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73a7076d-38b0-4edf-8c75-62f8b8c03c93 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73a7076d-38b0-4edf-8c75-62f8b8c03c93');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "combined_df = train_df.append(dev_df, ignore_index = True)\n",
        "combined_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "temporal-improvement",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "temporal-improvement",
        "outputId": "bc4969af-2772-408c-b85e-7fd6c2faa41b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4. Can eating garlic help prevent infection with the new coronavirus? #COVID19Malaysia https://t.co/q133xXBiwl 5. Can regularly rinsing your nose with saline help prevent infection with the new coronavirus? https://t.co/ccMjhhD7BK 6. Do vaccines against pneumonia protect you against the new coronavirus? https://t.co/wL0mlEqU95 7. Can spraying alcohol or chlorine all over your body kill the new coronavirus? #Chamber https://t.co/zunVR7Ht0V 8. How effective are thermal scanners in detecting people infected with the new coronavirus? https://t.co/nyLOyKAb1H 9. Can an ultraviolet disinfection lamp kill the new coronavirus? https://t.co/ZrlllbkIjm 10. Are hand dryers effective in killing the new coronavirus? https://t.co/cSDKXO1bGr 11. The new coronavirus CANNOT be transmitted through mosquito bites. https://t.co/ZRL8bjRkpl 12. Taking a hot bath does not prevent the new coronavirus disease https://t.co/bICOqSTOuD 13. Cold weather and snow CANNOT kill the new coronavirus. https://t.co/7yeQQ6gLNo 14. COVID-19 virus can be transmitted in areas with hot and humid climates https://t.co/ylKa2F40vu 15. Drinking alcohol does not protect you against COVID-19 and can be dangerous https://t.co/ZrLN61q046 16. Being able to hold your breath for 10 seconds or more without coughing or feeling discomfort DOES NOT mean you are free from the coronavirus disease (COVID-19) or any other lung disease. https://t.co/gPUL51Y2lx 17. You can recover from the coronavirus disease (COVID-19). Catching the new coronavirus DOES NOT mean you will have it for life. https://t.co/yrjUM5qniK 18. Exposing yourself to the sun or to temperatures higher than 25C degrees DOES NOT prevent the coronavirus disease (COVID-19) https://t.co/aOQKrrwaBv 19. 5G mobile networks DO NOT spread COVID-19 https://t.co/VjqelBmpTn'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "combined_df.text[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "prospective-saturday",
      "metadata": {
        "id": "prospective-saturday"
      },
      "outputs": [],
      "source": [
        "def prepare_dataloaders(combined_df, test_df, batch_size):    \n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False, normalization=True)\n",
        "\n",
        "    \n",
        "    tweet_train = bert_encode(combined_df, tokenizer)\n",
        "    tweet_train_labels = combined_df.label.astype(int)\n",
        "    \n",
        "    tweet_test = bert_encode(test_df, tokenizer)\n",
        "\n",
        "\n",
        "    input_ids, attention_masks = tweet_train.values()\n",
        "    labels = torch.tensor(tweet_train_labels.values)\n",
        "    train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    \n",
        "    input_ids, attention_masks = tweet_test.values()\n",
        "    test_dataset = TensorDataset(input_ids, attention_masks)\n",
        "\n",
        "    \n",
        "    train_dataloader = DataLoader(\n",
        "                train_dataset,\n",
        "                sampler = RandomSampler(train_dataset), \n",
        "                batch_size = batch_size \n",
        "            )\n",
        "\n",
        "    test_dataloader = DataLoader(\n",
        "                test_dataset, \n",
        "                sampler = SequentialSampler(test_dataset), \n",
        "                batch_size = batch_size\n",
        "            )\n",
        "    \n",
        "    return train_dataloader,test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dirty-boutique",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dirty-boutique",
        "outputId": "bda2baea-2ddb-43b5-a945-a6432652b429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "combined_dataloader,test_dataloader = prepare_dataloaders(combined_df, test_df, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "designing-snowboard",
      "metadata": {
        "id": "designing-snowboard",
        "outputId": "b51e1893-dc23-4da1-d1f9-304b605452c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "epochs = 7\n",
        "total_steps = len(combined_dataloader) * epochs\n",
        "\n",
        "model, optimizer, scheduler = prepare_model(num_classes=2, model_to_load = None, total_steps = total_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "flush-science",
      "metadata": {
        "id": "flush-science"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "impressive-netscape",
      "metadata": {
        "id": "impressive-netscape"
      },
      "outputs": [],
      "source": [
        "def train(model,optimizer,scheduler,train_dataloader,epochs):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model.to(device)\n",
        "\n",
        "    training_stats = []\n",
        "    total_t0 = time.time()\n",
        "\n",
        "    for epoch_i in range(0, epochs):\n",
        "\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training:')\n",
        "        \n",
        "        t0 = time.time()\n",
        "        total_train_loss = 0\n",
        "        model.train()\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "            model.zero_grad()        \n",
        "            outputs = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask, \n",
        "                                labels=b_labels)\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "            total_train_loss += loss.item()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "toxic-prize",
      "metadata": {
        "id": "toxic-prize",
        "outputId": "058516a3-fea5-44e1-f178-8681390f1b76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 7 ========\n",
            "Training:\n",
            "  Batch    40  of  1,161.    Elapsed: 0:00:12.\n",
            "  Batch    80  of  1,161.    Elapsed: 0:00:22.\n",
            "  Batch   120  of  1,161.    Elapsed: 0:00:33.\n",
            "  Batch   160  of  1,161.    Elapsed: 0:00:44.\n",
            "  Batch   200  of  1,161.    Elapsed: 0:00:54.\n",
            "  Batch   240  of  1,161.    Elapsed: 0:01:05.\n",
            "  Batch   280  of  1,161.    Elapsed: 0:01:16.\n",
            "  Batch   320  of  1,161.    Elapsed: 0:01:26.\n",
            "  Batch   360  of  1,161.    Elapsed: 0:01:37.\n",
            "  Batch   400  of  1,161.    Elapsed: 0:01:48.\n",
            "  Batch   440  of  1,161.    Elapsed: 0:01:58.\n",
            "  Batch   480  of  1,161.    Elapsed: 0:02:09.\n",
            "  Batch   520  of  1,161.    Elapsed: 0:02:20.\n",
            "  Batch   560  of  1,161.    Elapsed: 0:02:30.\n",
            "  Batch   600  of  1,161.    Elapsed: 0:02:41.\n",
            "  Batch   640  of  1,161.    Elapsed: 0:02:52.\n",
            "  Batch   680  of  1,161.    Elapsed: 0:03:02.\n",
            "  Batch   720  of  1,161.    Elapsed: 0:03:13.\n",
            "  Batch   760  of  1,161.    Elapsed: 0:03:24.\n",
            "  Batch   800  of  1,161.    Elapsed: 0:03:34.\n",
            "  Batch   840  of  1,161.    Elapsed: 0:03:45.\n",
            "  Batch   880  of  1,161.    Elapsed: 0:03:56.\n",
            "  Batch   920  of  1,161.    Elapsed: 0:04:06.\n",
            "  Batch   960  of  1,161.    Elapsed: 0:04:17.\n",
            "  Batch 1,000  of  1,161.    Elapsed: 0:04:28.\n",
            "  Batch 1,040  of  1,161.    Elapsed: 0:04:38.\n",
            "  Batch 1,080  of  1,161.    Elapsed: 0:04:49.\n",
            "  Batch 1,120  of  1,161.    Elapsed: 0:05:00.\n",
            "  Batch 1,160  of  1,161.    Elapsed: 0:05:10.\n",
            "\n",
            "  Training loss: 0.58\n",
            "  Training epoch took: 0:05:11\n",
            "\n",
            "======== Epoch 2 / 7 ========\n",
            "Training:\n",
            "  Batch    40  of  1,161.    Elapsed: 0:00:11.\n",
            "  Batch    80  of  1,161.    Elapsed: 0:00:21.\n",
            "  Batch   120  of  1,161.    Elapsed: 0:00:32.\n",
            "  Batch   160  of  1,161.    Elapsed: 0:00:42.\n",
            "  Batch   200  of  1,161.    Elapsed: 0:00:53.\n",
            "  Batch   240  of  1,161.    Elapsed: 0:01:04.\n",
            "  Batch   280  of  1,161.    Elapsed: 0:01:14.\n",
            "  Batch   320  of  1,161.    Elapsed: 0:01:25.\n",
            "  Batch   360  of  1,161.    Elapsed: 0:01:35.\n",
            "  Batch   400  of  1,161.    Elapsed: 0:01:46.\n",
            "  Batch   440  of  1,161.    Elapsed: 0:01:57.\n",
            "  Batch   480  of  1,161.    Elapsed: 0:02:07.\n",
            "  Batch   520  of  1,161.    Elapsed: 0:02:18.\n",
            "  Batch   560  of  1,161.    Elapsed: 0:02:28.\n",
            "  Batch   600  of  1,161.    Elapsed: 0:02:39.\n",
            "  Batch   640  of  1,161.    Elapsed: 0:02:49.\n",
            "  Batch   680  of  1,161.    Elapsed: 0:03:00.\n",
            "  Batch   720  of  1,161.    Elapsed: 0:03:11.\n",
            "  Batch   760  of  1,161.    Elapsed: 0:03:21.\n",
            "  Batch   800  of  1,161.    Elapsed: 0:03:32.\n",
            "  Batch   840  of  1,161.    Elapsed: 0:03:42.\n",
            "  Batch   880  of  1,161.    Elapsed: 0:03:53.\n",
            "  Batch   920  of  1,161.    Elapsed: 0:04:04.\n",
            "  Batch   960  of  1,161.    Elapsed: 0:04:14.\n",
            "  Batch 1,000  of  1,161.    Elapsed: 0:04:25.\n",
            "  Batch 1,040  of  1,161.    Elapsed: 0:04:35.\n",
            "  Batch 1,080  of  1,161.    Elapsed: 0:04:46.\n",
            "  Batch 1,120  of  1,161.    Elapsed: 0:04:56.\n",
            "  Batch 1,160  of  1,161.    Elapsed: 0:05:07.\n",
            "\n",
            "  Training loss: 0.47\n",
            "  Training epoch took: 0:05:07\n",
            "\n",
            "======== Epoch 3 / 7 ========\n",
            "Training:\n",
            "  Batch    40  of  1,161.    Elapsed: 0:00:10.\n",
            "  Batch    80  of  1,161.    Elapsed: 0:00:21.\n",
            "  Batch   120  of  1,161.    Elapsed: 0:00:32.\n",
            "  Batch   160  of  1,161.    Elapsed: 0:00:42.\n",
            "  Batch   200  of  1,161.    Elapsed: 0:00:53.\n",
            "  Batch   240  of  1,161.    Elapsed: 0:01:03.\n",
            "  Batch   280  of  1,161.    Elapsed: 0:01:14.\n",
            "  Batch   320  of  1,161.    Elapsed: 0:01:24.\n",
            "  Batch   360  of  1,161.    Elapsed: 0:01:35.\n",
            "  Batch   400  of  1,161.    Elapsed: 0:01:45.\n",
            "  Batch   440  of  1,161.    Elapsed: 0:01:56.\n",
            "  Batch   480  of  1,161.    Elapsed: 0:02:06.\n",
            "  Batch   520  of  1,161.    Elapsed: 0:02:17.\n",
            "  Batch   560  of  1,161.    Elapsed: 0:02:27.\n",
            "  Batch   600  of  1,161.    Elapsed: 0:02:38.\n",
            "  Batch   640  of  1,161.    Elapsed: 0:02:48.\n",
            "  Batch   680  of  1,161.    Elapsed: 0:02:59.\n",
            "  Batch   720  of  1,161.    Elapsed: 0:03:09.\n",
            "  Batch   760  of  1,161.    Elapsed: 0:03:20.\n",
            "  Batch   800  of  1,161.    Elapsed: 0:03:31.\n",
            "  Batch   840  of  1,161.    Elapsed: 0:03:41.\n",
            "  Batch   880  of  1,161.    Elapsed: 0:03:52.\n",
            "  Batch   920  of  1,161.    Elapsed: 0:04:02.\n",
            "  Batch   960  of  1,161.    Elapsed: 0:04:13.\n",
            "  Batch 1,000  of  1,161.    Elapsed: 0:04:23.\n",
            "  Batch 1,040  of  1,161.    Elapsed: 0:04:34.\n",
            "  Batch 1,080  of  1,161.    Elapsed: 0:04:44.\n",
            "  Batch 1,120  of  1,161.    Elapsed: 0:04:55.\n",
            "  Batch 1,160  of  1,161.    Elapsed: 0:05:05.\n",
            "\n",
            "  Training loss: 0.36\n",
            "  Training epoch took: 0:05:05\n",
            "\n",
            "======== Epoch 4 / 7 ========\n",
            "Training:\n",
            "  Batch    40  of  1,161.    Elapsed: 0:00:10.\n",
            "  Batch    80  of  1,161.    Elapsed: 0:00:21.\n",
            "  Batch   120  of  1,161.    Elapsed: 0:00:31.\n",
            "  Batch   160  of  1,161.    Elapsed: 0:00:42.\n",
            "  Batch   200  of  1,161.    Elapsed: 0:00:52.\n",
            "  Batch   240  of  1,161.    Elapsed: 0:01:03.\n",
            "  Batch   280  of  1,161.    Elapsed: 0:01:13.\n",
            "  Batch   320  of  1,161.    Elapsed: 0:01:24.\n",
            "  Batch   360  of  1,161.    Elapsed: 0:01:34.\n",
            "  Batch   400  of  1,161.    Elapsed: 0:01:45.\n",
            "  Batch   440  of  1,161.    Elapsed: 0:01:55.\n",
            "  Batch   480  of  1,161.    Elapsed: 0:02:06.\n",
            "  Batch   520  of  1,161.    Elapsed: 0:02:16.\n",
            "  Batch   560  of  1,161.    Elapsed: 0:02:27.\n",
            "  Batch   600  of  1,161.    Elapsed: 0:02:37.\n",
            "  Batch   640  of  1,161.    Elapsed: 0:02:48.\n",
            "  Batch   680  of  1,161.    Elapsed: 0:02:58.\n",
            "  Batch   720  of  1,161.    Elapsed: 0:03:09.\n",
            "  Batch   760  of  1,161.    Elapsed: 0:03:19.\n",
            "  Batch   800  of  1,161.    Elapsed: 0:03:30.\n",
            "  Batch   840  of  1,161.    Elapsed: 0:03:40.\n",
            "  Batch   880  of  1,161.    Elapsed: 0:03:51.\n",
            "  Batch   920  of  1,161.    Elapsed: 0:04:01.\n",
            "  Batch   960  of  1,161.    Elapsed: 0:04:12.\n",
            "  Batch 1,000  of  1,161.    Elapsed: 0:04:22.\n",
            "  Batch 1,040  of  1,161.    Elapsed: 0:04:32.\n",
            "  Batch 1,080  of  1,161.    Elapsed: 0:04:43.\n",
            "  Batch 1,120  of  1,161.    Elapsed: 0:04:53.\n",
            "  Batch 1,160  of  1,161.    Elapsed: 0:05:04.\n",
            "\n",
            "  Training loss: 0.27\n",
            "  Training epoch took: 0:05:04\n",
            "\n",
            "======== Epoch 5 / 7 ========\n",
            "Training:\n",
            "  Batch    40  of  1,161.    Elapsed: 0:00:10.\n",
            "  Batch    80  of  1,161.    Elapsed: 0:00:21.\n",
            "  Batch   120  of  1,161.    Elapsed: 0:00:31.\n",
            "  Batch   160  of  1,161.    Elapsed: 0:00:42.\n",
            "  Batch   200  of  1,161.    Elapsed: 0:00:52.\n",
            "  Batch   240  of  1,161.    Elapsed: 0:01:03.\n",
            "  Batch   280  of  1,161.    Elapsed: 0:01:13.\n",
            "  Batch   320  of  1,161.    Elapsed: 0:01:23.\n",
            "  Batch   360  of  1,161.    Elapsed: 0:01:34.\n",
            "  Batch   400  of  1,161.    Elapsed: 0:01:44.\n",
            "  Batch   440  of  1,161.    Elapsed: 0:01:55.\n",
            "  Batch   480  of  1,161.    Elapsed: 0:02:05.\n",
            "  Batch   520  of  1,161.    Elapsed: 0:02:16.\n",
            "  Batch   560  of  1,161.    Elapsed: 0:02:26.\n",
            "  Batch   600  of  1,161.    Elapsed: 0:02:37.\n",
            "  Batch   640  of  1,161.    Elapsed: 0:02:47.\n",
            "  Batch   680  of  1,161.    Elapsed: 0:02:57.\n",
            "  Batch   720  of  1,161.    Elapsed: 0:03:08.\n",
            "  Batch   760  of  1,161.    Elapsed: 0:03:18.\n",
            "  Batch   800  of  1,161.    Elapsed: 0:03:29.\n",
            "  Batch   840  of  1,161.    Elapsed: 0:03:39.\n",
            "  Batch   880  of  1,161.    Elapsed: 0:03:50.\n",
            "  Batch   920  of  1,161.    Elapsed: 0:04:00.\n",
            "  Batch   960  of  1,161.    Elapsed: 0:04:11.\n",
            "  Batch 1,000  of  1,161.    Elapsed: 0:04:21.\n",
            "  Batch 1,040  of  1,161.    Elapsed: 0:04:31.\n",
            "  Batch 1,080  of  1,161.    Elapsed: 0:04:42.\n",
            "  Batch 1,120  of  1,161.    Elapsed: 0:04:52.\n",
            "  Batch 1,160  of  1,161.    Elapsed: 0:05:03.\n",
            "\n",
            "  Training loss: 0.18\n",
            "  Training epoch took: 0:05:03\n",
            "\n",
            "======== Epoch 6 / 7 ========\n",
            "Training:\n",
            "  Batch    40  of  1,161.    Elapsed: 0:00:10.\n",
            "  Batch    80  of  1,161.    Elapsed: 0:00:21.\n",
            "  Batch   120  of  1,161.    Elapsed: 0:00:31.\n",
            "  Batch   160  of  1,161.    Elapsed: 0:00:42.\n",
            "  Batch   200  of  1,161.    Elapsed: 0:00:52.\n",
            "  Batch   240  of  1,161.    Elapsed: 0:01:02.\n",
            "  Batch   280  of  1,161.    Elapsed: 0:01:13.\n",
            "  Batch   320  of  1,161.    Elapsed: 0:01:23.\n",
            "  Batch   360  of  1,161.    Elapsed: 0:01:34.\n",
            "  Batch   400  of  1,161.    Elapsed: 0:01:44.\n",
            "  Batch   440  of  1,161.    Elapsed: 0:01:55.\n",
            "  Batch   480  of  1,161.    Elapsed: 0:02:05.\n",
            "  Batch   520  of  1,161.    Elapsed: 0:02:15.\n",
            "  Batch   560  of  1,161.    Elapsed: 0:02:26.\n",
            "  Batch   600  of  1,161.    Elapsed: 0:02:36.\n",
            "  Batch   640  of  1,161.    Elapsed: 0:02:47.\n",
            "  Batch   680  of  1,161.    Elapsed: 0:02:57.\n",
            "  Batch   720  of  1,161.    Elapsed: 0:03:07.\n",
            "  Batch   760  of  1,161.    Elapsed: 0:03:18.\n",
            "  Batch   800  of  1,161.    Elapsed: 0:03:28.\n",
            "  Batch   840  of  1,161.    Elapsed: 0:03:39.\n",
            "  Batch   880  of  1,161.    Elapsed: 0:03:49.\n",
            "  Batch   920  of  1,161.    Elapsed: 0:03:59.\n",
            "  Batch   960  of  1,161.    Elapsed: 0:04:10.\n",
            "  Batch 1,000  of  1,161.    Elapsed: 0:04:20.\n",
            "  Batch 1,040  of  1,161.    Elapsed: 0:04:31.\n",
            "  Batch 1,080  of  1,161.    Elapsed: 0:04:41.\n",
            "  Batch 1,120  of  1,161.    Elapsed: 0:04:52.\n",
            "  Batch 1,160  of  1,161.    Elapsed: 0:05:02.\n",
            "\n",
            "  Training loss: 0.13\n",
            "  Training epoch took: 0:05:02\n",
            "\n",
            "======== Epoch 7 / 7 ========\n",
            "Training:\n",
            "  Batch    40  of  1,161.    Elapsed: 0:00:10.\n",
            "  Batch    80  of  1,161.    Elapsed: 0:00:21.\n",
            "  Batch   120  of  1,161.    Elapsed: 0:00:31.\n",
            "  Batch   160  of  1,161.    Elapsed: 0:00:42.\n",
            "  Batch   200  of  1,161.    Elapsed: 0:00:52.\n",
            "  Batch   240  of  1,161.    Elapsed: 0:01:02.\n",
            "  Batch   280  of  1,161.    Elapsed: 0:01:13.\n",
            "  Batch   320  of  1,161.    Elapsed: 0:01:23.\n",
            "  Batch   360  of  1,161.    Elapsed: 0:01:34.\n",
            "  Batch   400  of  1,161.    Elapsed: 0:01:44.\n",
            "  Batch   440  of  1,161.    Elapsed: 0:01:55.\n",
            "  Batch   480  of  1,161.    Elapsed: 0:02:05.\n",
            "  Batch   520  of  1,161.    Elapsed: 0:02:15.\n",
            "  Batch   560  of  1,161.    Elapsed: 0:02:26.\n",
            "  Batch   600  of  1,161.    Elapsed: 0:02:36.\n",
            "  Batch   640  of  1,161.    Elapsed: 0:02:47.\n",
            "  Batch   680  of  1,161.    Elapsed: 0:02:57.\n",
            "  Batch   720  of  1,161.    Elapsed: 0:03:07.\n",
            "  Batch   760  of  1,161.    Elapsed: 0:03:18.\n",
            "  Batch   800  of  1,161.    Elapsed: 0:03:28.\n",
            "  Batch   840  of  1,161.    Elapsed: 0:03:39.\n",
            "  Batch   880  of  1,161.    Elapsed: 0:03:49.\n",
            "  Batch   920  of  1,161.    Elapsed: 0:03:59.\n",
            "  Batch   960  of  1,161.    Elapsed: 0:04:10.\n",
            "  Batch 1,000  of  1,161.    Elapsed: 0:04:20.\n",
            "  Batch 1,040  of  1,161.    Elapsed: 0:04:31.\n",
            "  Batch 1,080  of  1,161.    Elapsed: 0:04:41.\n",
            "  Batch 1,120  of  1,161.    Elapsed: 0:04:51.\n",
            "  Batch 1,160  of  1,161.    Elapsed: 0:05:02.\n",
            "\n",
            "  Training loss: 0.10\n",
            "  Training epoch took: 0:05:02\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:35:34 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "train(model,optimizer,scheduler,train_dataloader, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "scenic-monthly",
      "metadata": {
        "id": "scenic-monthly"
      },
      "outputs": [],
      "source": [
        "torch.save(model.cpu().roberta.state_dict(),\"./bertweet/bertweet_v35\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "outstanding-participation",
      "metadata": {
        "id": "outstanding-participation"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "brutal-burning",
      "metadata": {
        "id": "brutal-burning"
      },
      "outputs": [],
      "source": [
        "def predict(model,test_dataloader):\n",
        "    model.eval()\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model.to(device)\n",
        "    preds = []\n",
        "\n",
        "    for batch in test_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        for logit in logits:\n",
        "            preds.append(logit)\n",
        "\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "minor-wages",
      "metadata": {
        "id": "minor-wages"
      },
      "outputs": [],
      "source": [
        "result = predict(model,test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "found-caribbean",
      "metadata": {
        "id": "found-caribbean"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "pred_labels = np.argmax(result, axis = 1)\n",
        "\n",
        "pred_scores = softmax(result, axis=1)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stretch-wilson",
      "metadata": {
        "id": "stretch-wilson",
        "outputId": "db3bc254-2a84-4d0f-861e-536b3e89ac61"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>544382249178001408</td>\n",
              "      <td>rumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>525027317551079424</td>\n",
              "      <td>rumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>544273220128739329</td>\n",
              "      <td>rumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>499571799764770816</td>\n",
              "      <td>non-rumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>552844104418091008</td>\n",
              "      <td>non-rumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>553581227165642752</td>\n",
              "      <td>non-rumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577</th>\n",
              "      <td>552816302780579840</td>\n",
              "      <td>non-rumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>578</th>\n",
              "      <td>580350000074457088</td>\n",
              "      <td>rumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>579</th>\n",
              "      <td>498584409055174656</td>\n",
              "      <td>non-rumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>580</th>\n",
              "      <td>524961070465945600</td>\n",
              "      <td>non-rumour</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>581 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     id      target\n",
              "0    544382249178001408      rumour\n",
              "1    525027317551079424      rumour\n",
              "2    544273220128739329      rumour\n",
              "3    499571799764770816  non-rumour\n",
              "4    552844104418091008  non-rumour\n",
              "..                  ...         ...\n",
              "576  553581227165642752  non-rumour\n",
              "577  552816302780579840  non-rumour\n",
              "578  580350000074457088      rumour\n",
              "579  498584409055174656  non-rumour\n",
              "580  524961070465945600  non-rumour\n",
              "\n",
              "[581 rows x 2 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_labels = [convert_prediction(pred) for pred in pred_labels]\n",
        "\n",
        "output = pd.DataFrame({'id':test_df.id,'target':predicted_labels})\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "controversial-jamaica",
      "metadata": {
        "id": "controversial-jamaica"
      },
      "outputs": [],
      "source": [
        "submission = pd.Series(output.target.values,index=output.id).to_dict()\n",
        "with open('test-output.json', 'w') as f:\n",
        "    json.dump(submission, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "neural-resistance",
      "metadata": {
        "id": "neural-resistance"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "engaged-bearing",
      "metadata": {
        "id": "engaged-bearing"
      },
      "source": [
        "# Perform Inference on COVID dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "treated-qatar",
      "metadata": {
        "id": "treated-qatar"
      },
      "outputs": [],
      "source": [
        "covid_df = load_data(data_file = '../data/covid.data.jsonl', label_file = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acute-tribute",
      "metadata": {
        "id": "acute-tribute",
        "outputId": "ca363b0f-1ece-4cb4-c299-9587d3fe5b46"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1272262651100434433</td>\n",
              "      <td>According to the New York Times, Warner Bros. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1287153210990395392</td>\n",
              "      <td>Hurricane Hanna has made landfall in Texas.\\n\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1266555444283179008</td>\n",
              "      <td>Monkeys on the loose in India with stolen coro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1257715199655755779</td>\n",
              "      <td>Eastleigh and Swahili Arabs in Mombasa where c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1274338812173393920</td>\n",
              "      <td>“If Trump felt comfortable having it here, the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17453</th>\n",
              "      <td>1249502859185590272</td>\n",
              "      <td>I wonder how many lives could’ve been saved if...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17454</th>\n",
              "      <td>1284050414619459586</td>\n",
              "      <td>The @thetimes front page on 17th March. The fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17455</th>\n",
              "      <td>1274505289614725122</td>\n",
              "      <td>Trump just completed the racism trifecta in a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17456</th>\n",
              "      <td>1267884642637676545</td>\n",
              "      <td>Here are a few of my photographs from today’s ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17457</th>\n",
              "      <td>1265801718958301184</td>\n",
              "      <td>‘IT’S GONE’: Bill De Blasio Says NYC Facing $9...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17458 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        id                                               text\n",
              "0      1272262651100434433  According to the New York Times, Warner Bros. ...\n",
              "1      1287153210990395392  Hurricane Hanna has made landfall in Texas.\\n\\...\n",
              "2      1266555444283179008  Monkeys on the loose in India with stolen coro...\n",
              "3      1257715199655755779  Eastleigh and Swahili Arabs in Mombasa where c...\n",
              "4      1274338812173393920  “If Trump felt comfortable having it here, the...\n",
              "...                    ...                                                ...\n",
              "17453  1249502859185590272  I wonder how many lives could’ve been saved if...\n",
              "17454  1284050414619459586  The @thetimes front page on 17th March. The fi...\n",
              "17455  1274505289614725122  Trump just completed the racism trifecta in a ...\n",
              "17456  1267884642637676545  Here are a few of my photographs from today’s ...\n",
              "17457  1265801718958301184  ‘IT’S GONE’: Bill De Blasio Says NYC Facing $9...\n",
              "\n",
              "[17458 rows x 2 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "covid_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "induced-minister",
      "metadata": {
        "id": "induced-minister",
        "outputId": "31194557-c91d-4516-cbb5-d3e2cbda799f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2096: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "train_dataloader,covid_dataloader = prepare_dataloaders(combined_df, covid_df, batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "balanced-switzerland",
      "metadata": {
        "id": "balanced-switzerland"
      },
      "outputs": [],
      "source": [
        "result = predict(model,covid_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wireless-muscle",
      "metadata": {
        "id": "wireless-muscle"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "pred_labels = np.argmax(result, axis = 1)\n",
        "\n",
        "pred_scores = softmax(result, axis=1)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "precise-contrast",
      "metadata": {
        "id": "precise-contrast",
        "outputId": "34744f66-7e26-4d4f-f29d-dddec8ce1208"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "alert-choir",
      "metadata": {
        "id": "alert-choir",
        "outputId": "d29a4793-a810-4f8b-fd14-ed2de3476bd0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1272262651100434433</td>\n",
              "      <td>non-rumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1287153210990395392</td>\n",
              "      <td>non-rumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1266555444283179008</td>\n",
              "      <td>non-rumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1257715199655755779</td>\n",
              "      <td>non-rumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1274338812173393920</td>\n",
              "      <td>non-rumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17453</th>\n",
              "      <td>1249502859185590272</td>\n",
              "      <td>non-rumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17454</th>\n",
              "      <td>1284050414619459586</td>\n",
              "      <td>non-rumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17455</th>\n",
              "      <td>1274505289614725122</td>\n",
              "      <td>non-rumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17456</th>\n",
              "      <td>1267884642637676545</td>\n",
              "      <td>non-rumour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17457</th>\n",
              "      <td>1265801718958301184</td>\n",
              "      <td>non-rumour</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17458 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        id      target\n",
              "0      1272262651100434433  non-rumour\n",
              "1      1287153210990395392  non-rumour\n",
              "2      1266555444283179008  non-rumour\n",
              "3      1257715199655755779  non-rumour\n",
              "4      1274338812173393920  non-rumour\n",
              "...                    ...         ...\n",
              "17453  1249502859185590272  non-rumour\n",
              "17454  1284050414619459586  non-rumour\n",
              "17455  1274505289614725122  non-rumour\n",
              "17456  1267884642637676545  non-rumour\n",
              "17457  1265801718958301184  non-rumour\n",
              "\n",
              "[17458 rows x 2 columns]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_labels = [convert_prediction(pred) for pred in pred_labels]\n",
        "\n",
        "output = pd.DataFrame({'id':covid_df.id,'target':predicted_labels})\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "interested-martial",
      "metadata": {
        "id": "interested-martial"
      },
      "outputs": [],
      "source": [
        "submission = pd.Series(output.target.values,index=output.id).to_dict()\n",
        "with open('covid-output.json', 'w') as f:\n",
        "    json.dump(submission, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "becoming-purpose",
      "metadata": {
        "id": "becoming-purpose"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "environment": {
      "name": "tf2-gpu.2-3.m65",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "SR_rumour_detection_bertweet.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c8be21b5fe14fc5a5fc54855072b70c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ae1a184017d4d7e82c085532d81fc4f",
              "IPY_MODEL_d651412732d449fe840380a02ddd87e7",
              "IPY_MODEL_c69a2b728a88477fa89c74594076da3d"
            ],
            "layout": "IPY_MODEL_2fe5e907495e4ee187dd8011e9483c4c"
          }
        },
        "1ae1a184017d4d7e82c085532d81fc4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3315aeae8e8b431cb3634c5574a45502",
            "placeholder": "​",
            "style": "IPY_MODEL_1e2e2f83874340eeb944904dcbfd853b",
            "value": "Downloading: 100%"
          }
        },
        "d651412732d449fe840380a02ddd87e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2e7edc905a44febbed9e9810d9f21b1",
            "max": 558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f447f3fdffe410b844eb7066e76ced6",
            "value": 558
          }
        },
        "c69a2b728a88477fa89c74594076da3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d09f84fb1da4c649975beb2bb040675",
            "placeholder": "​",
            "style": "IPY_MODEL_ed136a5a4c8848d2a2eb23fa1dbe0727",
            "value": " 558/558 [00:00&lt;00:00, 17.5kB/s]"
          }
        },
        "2fe5e907495e4ee187dd8011e9483c4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3315aeae8e8b431cb3634c5574a45502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e2e2f83874340eeb944904dcbfd853b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2e7edc905a44febbed9e9810d9f21b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f447f3fdffe410b844eb7066e76ced6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d09f84fb1da4c649975beb2bb040675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed136a5a4c8848d2a2eb23fa1dbe0727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1198d058f938423f89963e538093b473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a747d567db84426dbe8663100bab51c0",
              "IPY_MODEL_d71ba793790340089d15ed43c074f9a7",
              "IPY_MODEL_794c99e8c3e64120aaa9648e9512a294"
            ],
            "layout": "IPY_MODEL_048c476a999b4e6ab47d6870e9708333"
          }
        },
        "a747d567db84426dbe8663100bab51c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b825bfaafc0479c80864c6b8a92ccac",
            "placeholder": "​",
            "style": "IPY_MODEL_d1791a34dc534a77a7b9263b62fdfd2f",
            "value": "Downloading: 100%"
          }
        },
        "d71ba793790340089d15ed43c074f9a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d4775b074cd403080e10d741c50c2de",
            "max": 843438,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1c14de71bd44c2bbc0cde8d2e22910c",
            "value": 843438
          }
        },
        "794c99e8c3e64120aaa9648e9512a294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47f3aaabed6d4908ae1e3065f161aa4f",
            "placeholder": "​",
            "style": "IPY_MODEL_da266a1bc3aa479caf6da49bd96b507d",
            "value": " 824k/824k [00:00&lt;00:00, 2.10MB/s]"
          }
        },
        "048c476a999b4e6ab47d6870e9708333": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b825bfaafc0479c80864c6b8a92ccac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1791a34dc534a77a7b9263b62fdfd2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d4775b074cd403080e10d741c50c2de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1c14de71bd44c2bbc0cde8d2e22910c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47f3aaabed6d4908ae1e3065f161aa4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da266a1bc3aa479caf6da49bd96b507d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5aefc10f6e14037aaaf2eef70db4c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cab0e718082f428da7e14dbf8c5de734",
              "IPY_MODEL_16adb8dc6e2741f09a7b7b9a32277778",
              "IPY_MODEL_949debd66e144e8f8ac3da8d4aec78e9"
            ],
            "layout": "IPY_MODEL_c6bf08c9bb7d4bdd9391ba3aa10f4504"
          }
        },
        "cab0e718082f428da7e14dbf8c5de734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22f457e4e85a44268b07f73fcf500c8a",
            "placeholder": "​",
            "style": "IPY_MODEL_67762459000640f4be90463b5404a943",
            "value": "Downloading: 100%"
          }
        },
        "16adb8dc6e2741f09a7b7b9a32277778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8a71638edb84544a912905ec112dc7f",
            "max": 1078931,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4fe672df31546588a2b5133ba455ab2",
            "value": 1078931
          }
        },
        "949debd66e144e8f8ac3da8d4aec78e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5cc96e7634f4bc68c7534bfb0d43f75",
            "placeholder": "​",
            "style": "IPY_MODEL_232a4a0eedbf4eff97ec2c3d76dd75fe",
            "value": " 1.03M/1.03M [00:00&lt;00:00, 1.94MB/s]"
          }
        },
        "c6bf08c9bb7d4bdd9391ba3aa10f4504": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22f457e4e85a44268b07f73fcf500c8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67762459000640f4be90463b5404a943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8a71638edb84544a912905ec112dc7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4fe672df31546588a2b5133ba455ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5cc96e7634f4bc68c7534bfb0d43f75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "232a4a0eedbf4eff97ec2c3d76dd75fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}